#!/usr/bin/env python3
"""
Script to analyze and display chunk counts for each parser-chunker combination.
Creates a nice table showing the total number of chunks generated by each parser and chunker.
"""

import json
import os
import glob
from collections import defaultdict
from tabulate import tabulate
import argparse


def load_chunk_file(json_path):
    """Load a chunk JSON file and return the number of chunks."""
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return len(data.get("chunks", []))
    except Exception as e:
        print(f"Error loading {json_path}: {e}")
        return 0


def analyze_chunk_counts(chunks_base_dir):
    """
    Analyze chunk counts across all parser-chunker-overlap combinations.
    
    Args:
        chunks_base_dir: Base directory containing chunked data
        
    Returns:
        Dictionary with parser-chunker-overlap combinations and their statistics
    """
    results = defaultdict(lambda: {
        'total_chunks': 0,
        'total_files': 0,
        'avg_chunks_per_file': 0,
        'min_chunks': float('inf'),
        'max_chunks': 0
    })
    
    # Get all parsers
    if not os.path.exists(chunks_base_dir):
        print(f"Directory {chunks_base_dir} does not exist!")
        return results
    
    parsers = [d for d in os.listdir(chunks_base_dir) 
               if os.path.isdir(os.path.join(chunks_base_dir, d))]
    
    print(f"Found parsers: {parsers}")
    
    for parser in parsers:
        parser_path = os.path.join(chunks_base_dir, parser)
        
        # Get all chunkers for this parser
        chunkers = [d for d in os.listdir(parser_path) 
                   if os.path.isdir(os.path.join(parser_path, d))]
        
        print(f"  Found chunkers for {parser}: {chunkers}")
        
        for chunker in chunkers:
            chunker_path = os.path.join(parser_path, chunker)
            
            # Get all overlap directories for this chunker
            overlap_dirs = [d for d in os.listdir(chunker_path) 
                           if os.path.isdir(os.path.join(chunker_path, d)) and d.startswith('overlap_')]
            
            print(f"    Found overlap dirs for {parser}-{chunker}: {overlap_dirs}")
            
            for overlap_dir in overlap_dirs:
                overlap_path = os.path.join(chunker_path, overlap_dir)
                overlap_value = overlap_dir.replace('overlap_', '')
                key = f"{parser}-{chunker}-{overlap_value}"
                
                # Get all JSON files in this overlap directory
                json_files = glob.glob(os.path.join(overlap_path, "*.json"))
                
                file_chunk_counts = []
                total_chunks = 0
                
                for json_file in json_files:
                    chunk_count = load_chunk_file(json_file)
                    file_chunk_counts.append(chunk_count)
                    total_chunks += chunk_count
                
                if file_chunk_counts:
                    results[key] = {
                        'total_chunks': total_chunks,
                        'total_files': len(file_chunk_counts),
                        'avg_chunks_per_file': round(total_chunks / len(file_chunk_counts), 2),
                        'min_chunks': min(file_chunk_counts),
                        'max_chunks': max(file_chunk_counts)
                    }
    
    return results


def create_summary_table(results):
    """Create a summary table showing total chunks and files for each combination."""
    headers = ["Parser", "Chunker", "Overlap", "Total Files", "Total Chunks", "Avg Chunks/File", "Min Chunks", "Max Chunks"]
    table_data = []
    
    for key, stats in sorted(results.items()):
        parts = key.split('-')
        if len(parts) >= 3:
            parser = parts[0]
            chunker = parts[1]
            overlap = parts[2]
        else:
            # Fallback for old format
            parser, chunker = key.split('-', 1)
            overlap = "N/A"
        
        table_data.append([
            parser,
            chunker,
            overlap,
            stats['total_files'],
            stats['total_chunks'],
            stats['avg_chunks_per_file'],
            stats['min_chunks'],
            stats['max_chunks']
        ])
    
    return tabulate(table_data, headers=headers, tablefmt="grid")


def create_pivot_table(results):
    """Create a pivot table with parsers as rows and chunker-overlap combinations as columns."""
    # Get unique parsers and chunker-overlap combinations
    parsers = set()
    chunker_overlaps = set()
    
    for key in results.keys():
        parts = key.split('-')
        if len(parts) >= 3:
            parser = parts[0]
            chunker = parts[1]
            overlap = parts[2]
            parsers.add(parser)
            chunker_overlaps.add(f"{chunker}-{overlap}")
        else:
            # Fallback for old format
            parser, chunker = key.split('-', 1)
            parsers.add(parser)
            chunker_overlaps.add(chunker)
    
    parsers = sorted(parsers)
    chunker_overlaps = sorted(chunker_overlaps)
    
    # Create pivot table data
    headers = ["Parser"] + chunker_overlaps
    table_data = []
    
    for parser in parsers:
        row = [parser]
        for chunker_overlap in chunker_overlaps:
            # Try to find matching key
            found = False
            for key in results.keys():
                if key.startswith(f"{parser}-{chunker_overlap}") or key == f"{parser}-{chunker_overlap}":
                    row.append(f"{results[key]['total_chunks']} ({results[key]['total_files']})")
                    found = True
                    break
            if not found:
                row.append("N/A")
        table_data.append(row)
    
    return tabulate(table_data, headers=headers, tablefmt="grid")


def main():
    dataset = 'financebench' # financebench
    parser = argparse.ArgumentParser(description='Analyze chunk counts across parser-chunker combinations')
    parser.add_argument('--chunks-dir', 
                       default=f'new_scripts/data/parsed_pages_chunks/{dataset}',
                       help='Base directory containing chunked data')
    parser.add_argument('--output', 
                       choices=['summary', 'pivot', 'both'], 
                       default='both',
                       help='Type of output to generate')
    
    args = parser.parse_args()
    
    # Convert to absolute path if relative
    chunks_dir = os.path.abspath(args.chunks_dir) if not os.path.isabs(args.chunks_dir) else args.chunks_dir
    
    print(f"Analyzing chunk counts in: {chunks_dir}")
    print("=" * 80)
    
    # Analyze the data
    results = analyze_chunk_counts(chunks_dir)
    
    if not results:
        print("No chunked data found!")
        return
    
    # Display results
    if args.output in ['summary', 'both']:
        print("\nðŸ“Š DETAILED SUMMARY TABLE")
        print("=" * 80)
        print(create_summary_table(results))
    
    if args.output in ['pivot', 'both']:
        print("\nðŸ“ˆ PIVOT TABLE (Total Chunks (Files))")
        print("=" * 80)
        print("Note: Columns show chunker-overlap combinations")
        print(create_pivot_table(results))
    
    # Print some overall statistics
    total_files = sum(stats['total_files'] for stats in results.values())
    total_chunks = sum(stats['total_chunks'] for stats in results.values())
    
    print(f"\nðŸ“‹ OVERALL STATISTICS")
    print("=" * 80)
    print(f"Total combinations analyzed: {len(results)}")
    print(f"Total files processed: {total_files}")
    print(f"Total chunks generated: {total_chunks}")
    
    if total_files > 0:
        print(f"Average chunks per file (overall): {total_chunks / total_files:.2f}")


if __name__ == '__main__':
    main()
